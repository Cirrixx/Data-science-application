{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOEID\n",
      "10001     874.943172\n",
      "10002    2020.718000\n",
      "10003    3262.795404\n",
      "10004    1635.520810\n",
      "10005     517.198730\n",
      "            ...     \n",
      "15682     322.870000\n",
      "15683     778.336484\n",
      "15684     599.547014\n",
      "15685    2319.422052\n",
      "15686    1808.603200\n",
      "Name: 2022_price, Length: 5686, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "import sklearn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#load data \n",
    "energy_data = pd.read_csv(\"recs2015_public_v4.csv\", index_col = \"DOEID\")\n",
    "energy_data.head()\n",
    "\n",
    "#add new column to dataset based on US national energy prices as of July 2022.\n",
    "def price_convertor(row):\n",
    "    \"\"\"calculates yearly energy cost in dollars\"\"\"\n",
    "    current_cost = row * 0.166 #multiplies kilowatthours used between 01/01/2015-31/12/2015 by US energy prices in July 2022\n",
    "    return current_cost\n",
    "\n",
    "energy_data[\"2022_price\"] = energy_data[\"KWH\"].apply(price_convertor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#check if any rows are missing target data. Other columns assessed later to avoid data leakage.  \n",
    "missing_target = energy_data[\"KWH\"].isnull().sum()\n",
    "print(missing_target) #no issue -> therefore no need to remove any \n",
    "\n",
    "#seperate target data column from dataset\n",
    "y = energy_data[\"KWH\"]\n",
    "\n",
    "\n",
    "#break off validation set from training data \n",
    "X_train_full, X_valid_full, y_train, y_valid = sklearn.model_selection.train_test_split(energy_data, y, train_size = 0.8, test_size = 0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['METROMICRO', 'UATYP10', 'CLIMATE_REGION_PUB', 'IECC_CLIMATE_PUB']\n"
     ]
    }
   ],
   "source": [
    "cols = energy_data.loc[\"REGIONC\":\"TOTSQFT_EN\"] #selects all possible predictor columns \n",
    "\n",
    "X_train = X_train_full[cols]\n",
    "X_valid = X_valid_full[cols]\n",
    "\n",
    "#check if any columns contain characters\n",
    "s = (X_train.dtypes == \"object\")\n",
    "object_cols = list(s[s].index)\n",
    "print(object_cols) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found 4 columns contain characters. These columns will be one-hot encoded to convert them into a number. \n",
    "\n",
    "Note that dataset had already been imputed, therefore this step was skipped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing for categorical data\n",
    "categorical_transformer = sklearn.pipeline.Pipeline(steps = [\n",
    "    (\"imputer\", sklearn.impute.SimpleImputer(strategy = \"most_frequent\")),\n",
    "    (\"onehot\", sklearn.preprocessing.OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Model \n",
    "Uses full set of variables to predict energy usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#create values to alternate through to check for best parameters\n",
    "N_VALUES = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "LEARNING_VALUES = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "#create dictionary to assign results to \n",
    "model_dict = {}\n",
    "\n",
    "#create function for comparing lots of models\n",
    "\n",
    "def get_score(n_value, learning_value):\n",
    "\n",
    "    model = XGBRegressor(n_estimators = n_value, early_stopping_rounds = 5, learning_rate = learning_value, n_jobs = 4)\n",
    "\n",
    "    #create pipeline \n",
    "    my_pipeline = sklearn.pipeline.Pipeline(steps =[\n",
    "        (\"categorical_transformer\", categorical_transformer),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "for n_value in N_VALUES:\n",
    "    for learning_value in LEARNING_VALUES: \n",
    "        \n",
    "        \n",
    "\n",
    "        #fit model \n",
    "        my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "        #get predictions \n",
    "\n",
    "        predictions = my_pipeline.predict(X_valid)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44d185f371fdda112848cc952b3838de71c0600367086048220c58996696b225"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
