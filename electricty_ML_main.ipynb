{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "import sklearn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#load data \n",
    "energy_data = pd.read_csv(\"recs2015_public_v4.csv\", index_col = \"DOEID\")\n",
    "energy_data.head()\n",
    "\n",
    "#add new column to dataset based on US national energy prices as of July 2022.\n",
    "def price_convertor(row):\n",
    "    \"\"\"calculates yearly energy cost in dollars\"\"\"\n",
    "    current_cost = row * 0.166 #multiplies kilowatthours used between 01/01/2015-31/12/2015 by US energy prices in July 2022\n",
    "    return current_cost\n",
    "\n",
    "energy_data[\"2022_price\"] = energy_data[\"KWH\"].apply(price_convertor)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#check if any rows are missing target data. Other columns assessed later to avoid data leakage.  \n",
    "missing_target = energy_data[\"KWH\"].isnull().sum()\n",
    "print(missing_target) #no issue -> therefore no need to remove any \n",
    "\n",
    "#seperate target data column from dataset\n",
    "y = energy_data[\"KWH\"]\n",
    "\n",
    "\n",
    "#break off predictor columns of interest\n",
    "X = energy_data.loc[:,\"REGIONC\":\"TOTSQFT_EN\"] #selects all possible predictor columns \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['METROMICRO', 'UATYP10']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#check if any columns contain characters\n",
    "s = (X.dtypes == \"object\")\n",
    "object_cols = list(s[s].index)\n",
    "print(object_cols) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found 2 columns contain characters. These columns will be one-hot encoded to convert them into a number. \n",
    "\n",
    "Note that dataset had already been imputed, therefore this step was skipped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing for categorical data\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "categorical_transformer = Pipeline(steps = [\n",
    "    (\"imputer\", SimpleImputer(strategy = \"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers = [(\"cat\", categorical_transformer, object_cols)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Model \n",
    "Uses full set of variables to predict energy usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5071.770917122756\n",
      "5071.770917122756\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\evanm\\OneDrive\\Documents\\Python resources\\Machine learning\\electricty_ML_main.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mfor\u001b[39;00m n_value \u001b[39min\u001b[39;00m N_VALUES:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mfor\u001b[39;00m learning_value \u001b[39min\u001b[39;00m LEARNING_VALUES: \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         score \u001b[39m=\u001b[39m get_score(n_value, learning_value)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#W6sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         all_values\u001b[39m.\u001b[39mappend(score)\n",
      "\u001b[1;32mc:\\Users\\evanm\\OneDrive\\Documents\\Python resources\\Machine learning\\electricty_ML_main.ipynb Cell 7\u001b[0m in \u001b[0;36mget_score\u001b[1;34m(n_value, learning_value)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m my_pipeline \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mpipeline\u001b[39m.\u001b[39mPipeline(steps \u001b[39m=\u001b[39m[\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mpreprocessor\u001b[39m\u001b[39m\"\u001b[39m, preprocessor),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, RandomForestRegressor(n_estimators \u001b[39m=\u001b[39m n_value, random_state \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, criterion \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabsolute_error\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m#assess model using cross-validation\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m scores \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m*\u001b[39m cross_val_score(my_pipeline, X, y, cv \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m, scoring \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mneg_mean_absolute_error\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(scores\u001b[39m.\u001b[39mmean())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mreturn\u001b[39;00m(scores\u001b[39m.\u001b[39mmean())\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[0;32m    269\u001b[0m         X,\n\u001b[0;32m    270\u001b[0m         y,\n\u001b[0;32m    271\u001b[0m         scorers,\n\u001b[0;32m    272\u001b[0m         train,\n\u001b[0;32m    273\u001b[0m         test,\n\u001b[0;32m    274\u001b[0m         verbose,\n\u001b[0;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    276\u001b[0m         fit_params,\n\u001b[0;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    281\u001b[0m     )\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    381\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 382\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    465\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    466\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    467\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    468\u001b[0m ]\n\u001b[0;32m    470\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 476\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    477\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    478\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    479\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    480\u001b[0m )(\n\u001b[0;32m    481\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    482\u001b[0m         t,\n\u001b[0;32m    483\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    484\u001b[0m         X,\n\u001b[0;32m    485\u001b[0m         y,\n\u001b[0;32m    486\u001b[0m         sample_weight,\n\u001b[0;32m    487\u001b[0m         i,\n\u001b[0;32m    488\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    489\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    490\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    491\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    492\u001b[0m     )\n\u001b[0;32m    493\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    494\u001b[0m )\n\u001b[0;32m    496\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "\n",
    "#create values to alternate through to check for best parameters\n",
    "N_VALUES = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "LEARNING_VALUES = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "#create dictionary to assign results to \n",
    "model_dict = {}\n",
    "all_values  = []\n",
    "#create function for comparing lots of models\n",
    "\n",
    "def get_score(n_value, learning_value):\n",
    "\n",
    "    #model = XGBRegressor(n_estimators = n_value,  learning_rate = learning_value, n_jobs = 4)\n",
    "\n",
    "    #create pipeline \n",
    "    my_pipeline = sklearn.pipeline.Pipeline(steps =[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model\", RandomForestRegressor(n_estimators = n_value, random_state = 0, n_jobs = -1, criterion = \"absolute_error\"))\n",
    "    ])\n",
    "\n",
    "    #assess model using cross-validation\n",
    "    scores = -1* cross_val_score(my_pipeline, X, y, cv = 5, scoring = \"neg_mean_absolute_error\")\n",
    "    print(scores.mean())\n",
    "    return(scores.mean())\n",
    "\n",
    "for n_value in N_VALUES:\n",
    "    for learning_value in LEARNING_VALUES: \n",
    "        score = get_score(n_value, learning_value)\n",
    "\n",
    "        all_values.append(score)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model currently uses an infeasibly high number of features. Not only does this mean the model is impractical for any real-world applications, but it may also reduce the model's accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGdCAYAAADuR1K7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAArKUlEQVR4nO3df3RUdX7/8Vd+kIyoCUqWDLDBsGskICEpgYShtnQPcxzctBp3izHHI5hy2KMVlt146CYUE/fQnmj3QGFLjhxaWd2esqFpNbXAZjc7CtUlgiShml1ldY8aCkwCeshAXBPNfL5/+GVkYIKZkGQmnzwf59wj3vu+n/l8PnNn5pWbeydxxhgjAAAAS8RHuwMAAADDiXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALBKYrQ7MBwCgYBOnTqlG2+8UXFxcdHuDgAAGARjjM6fP69p06YpPn74zrdYEW5OnTqljIyMaHcDAAAMwYkTJ/TVr3512NqzItzceOONkj6fnJSUlCj3BgAADIbf71dGRkbwc3y4WBFuLv4qKiUlhXADAMAYM9yXlHBBMQAAsMqQwk1tba0yMzPlcDhUWFioI0eOXLW+vr5e2dnZcjgcysnJ0f79+0O2x8XFhV1+9KMfDaV7AABgHIs43OzZs0fl5eWqrq5Wa2urcnNz5fF41NXVFbb+0KFDKi0t1apVq9TW1qbi4mIVFxervb09WHP69OmQZdeuXYqLi9O3v/3toY8MAACMS3HGGBPJDoWFhVq4cKG2b98u6fPbsDMyMrR27VpVVFRcUV9SUqKenh7t3bs3uG7RokXKy8vTjh07wj5GcXGxzp8/L6/XO6g++f1+paamqru7m2tuAAAYI0bq8zuiMzd9fX1qaWmR2+3+ooH4eLndbjU3N4fdp7m5OaRekjwez4D1nZ2d2rdvn1atWjVgP3p7e+X3+0MWAAAAKcJwc/bsWfX39ys9PT1kfXp6unw+X9h9fD5fRPXPPfecbrzxRn3rW98asB81NTVKTU0NLnzHDQAAuCjm7pbatWuXHnjgATkcjgFrKisr1d3dHVxOnDgxij0EAACxLKLvuUlLS1NCQoI6OztD1nd2dsrpdIbdx+l0Drr+lVde0fHjx7Vnz56r9iM5OVnJycmRdB0AAIwTEZ25SUpKUn5+fsiFvoFAQF6vVy6XK+w+LpfriguDm5qawtY/88wzys/PV25ubiTdAgAACIr4G4rLy8u1cuVKLViwQAUFBdq6dat6enpUVlYmSVqxYoWmT5+umpoaSdK6deu0ZMkSbd68WUVFRaqrq9PRo0e1c+fOkHb9fr/q6+u1efPmYRgWAAAYryIONyUlJTpz5oyqqqrk8/mUl5enxsbG4EXDHR0dIX/Zc/Hixdq9e7c2btyoDRs2KCsrSw0NDZo7d25Iu3V1dTLGqLS09BqHBAAAxrOIv+cmFvE9NwAAjD0x8T03AAAAsY5wAwAArEK4ARCzMiv2RbsLAMYgwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqwwp3NTW1iozM1MOh0OFhYU6cuTIVevr6+uVnZ0th8OhnJwc7d+//4qat956S3fffbdSU1N1/fXXa+HChero6BhK9wAAwDgWcbjZs2ePysvLVV1drdbWVuXm5srj8airqyts/aFDh1RaWqpVq1apra1NxcXFKi4uVnt7e7Dm97//ve644w5lZ2frwIEDeuONN/T444/L4XAMfWQAAGBcijPGmEh2KCws1MKFC7V9+3ZJUiAQUEZGhtauXauKioor6ktKStTT06O9e/cG1y1atEh5eXnasWOHJOn+++/XhAkT9K//+q9DGoTf71dqaqq6u7uVkpIypDYAxJ7Min16/8miaHcDwAgZqc/viM7c9PX1qaWlRW63+4sG4uPldrvV3Nwcdp/m5uaQeknyeDzB+kAgoH379um2226Tx+PRlClTVFhYqIaGhgH70dvbK7/fH7IAAABIEYabs2fPqr+/X+np6SHr09PT5fP5wu7j8/muWt/V1aULFy7oySef1LJly/TLX/5S9957r771rW/p4MGDYdusqalRampqcMnIyIhkGEOWWbFvVB4HAAAMXdTvlgoEApKke+65R9///veVl5eniooK/fmf/3nw11aXq6ysVHd3d3A5ceLEaHYZAADEsMRIitPS0pSQkKDOzs6Q9Z2dnXI6nWH3cTqdV61PS0tTYmKi5syZE1Ize/Zsvfrqq2HbTE5OVnJyciRdBwAA40REZ26SkpKUn58vr9cbXBcIBOT1euVyucLu43K5QuolqampKViflJSkhQsX6vjx4yE1v/vd73TLLbdE0j0AAIDIztxIUnl5uVauXKkFCxaooKBAW7duVU9Pj8rKyiRJK1as0PTp01VTUyNJWrdunZYsWaLNmzerqKhIdXV1Onr0qHbu3Blsc/369SopKdGf/umf6hvf+IYaGxv13//93zpw4MDwjBIAAIwbEYebkpISnTlzRlVVVfL5fMrLy1NjY2PwouGOjg7Fx39xQmjx4sXavXu3Nm7cqA0bNigrK0sNDQ2aO3dusObee+/Vjh07VFNTo+9+97uaNWuW/vM//1N33HHHMAwRAACMJxF/z00sGq3vueE7N4DRxWsOsFtMfM8NAABArCPcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYZUripra1VZmamHA6HCgsLdeTIkavW19fXKzs7Ww6HQzk5Odq/f3/I9oceekhxcXEhy7Jly4bSNQAAMM5FHG727Nmj8vJyVVdXq7W1Vbm5ufJ4POrq6gpbf+jQIZWWlmrVqlVqa2tTcXGxiouL1d7eHlK3bNkynT59Orj87Gc/G9qIAADAuBZxuNmyZYtWr16tsrIyzZkzRzt27NDEiRO1a9eusPXbtm3TsmXLtH79es2ePVubNm3S/PnztX379pC65ORkOZ3O4HLTTTcNbUQAAGBciyjc9PX1qaWlRW63+4sG4uPldrvV3Nwcdp/m5uaQeknyeDxX1B84cEBTpkzRrFmz9Mgjj+jDDz8csB+9vb3y+/0hCwAAgBRhuDl79qz6+/uVnp4esj49PV0+ny/sPj6f70vrly1bpp/+9Kfyer166qmndPDgQd11113q7+8P22ZNTY1SU1ODS0ZGRiTDAAAAFkuMdgck6f777w/+OycnR/PmzdPXv/51HThwQEuXLr2ivrKyUuXl5cH/9/v9BBwAACApwjM3aWlpSkhIUGdnZ8j6zs5OOZ3OsPs4nc6I6iXpa1/7mtLS0vTuu++G3Z6cnKyUlJSQBQAAQIow3CQlJSk/P19erze4LhAIyOv1yuVyhd3H5XKF1EtSU1PTgPWS9H//93/68MMPNXXq1Ei6BwAAEPndUuXl5frnf/5nPffcc3rrrbf0yCOPqKenR2VlZZKkFStWqLKyMli/bt06NTY2avPmzXr77bf1xBNP6OjRo1qzZo0k6cKFC1q/fr1ee+01vf/++/J6vbrnnnt06623yuPxDNMwAQDAeBHxNTclJSU6c+aMqqqq5PP5lJeXp8bGxuBFwx0dHYqP/yIzLV68WLt379bGjRu1YcMGZWVlqaGhQXPnzpUkJSQk6I033tBzzz2nc+fOadq0abrzzju1adMmJScnD9MwAQDAeBFnjDHR7sS18vv9Sk1NVXd394hef5NZsU/vP1k0Yu0DCMVrDrDbSH1+87elAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFWGFG5qa2uVmZkph8OhwsJCHTly5Kr19fX1ys7OlsPhUE5Ojvbv3z9g7cMPP6y4uDht3bp1KF0DAADjXMThZs+ePSovL1d1dbVaW1uVm5srj8ejrq6usPWHDh1SaWmpVq1apba2NhUXF6u4uFjt7e1X1L7wwgt67bXXNG3atMhHAgAAoCGEmy1btmj16tUqKyvTnDlztGPHDk2cOFG7du0KW79t2zYtW7ZM69ev1+zZs7Vp0ybNnz9f27dvD6k7efKk1q5dq3/7t3/ThAkThjYaAAAw7kUUbvr6+tTS0iK32/1FA/Hxcrvdam5uDrtPc3NzSL0keTyekPpAIKAHH3xQ69ev1+233/6l/ejt7ZXf7w9ZAAAApAjDzdmzZ9Xf36/09PSQ9enp6fL5fGH38fl8X1r/1FNPKTExUd/97ncH1Y+amhqlpqYGl4yMjEiGAQAALBb1u6VaWlq0bds2Pfvss4qLixvUPpWVleru7g4uJ06cGOFeAgCAsSKicJOWlqaEhAR1dnaGrO/s7JTT6Qy7j9PpvGr9K6+8oq6uLs2YMUOJiYlKTEzUBx98oMcee0yZmZlh20xOTlZKSkrIAgAAIEUYbpKSkpSfny+v1xtcFwgE5PV65XK5wu7jcrlC6iWpqakpWP/ggw/qjTfe0LFjx4LLtGnTtH79ev3iF7+IdDwAAGCcS4x0h/Lycq1cuVILFixQQUGBtm7dqp6eHpWVlUmSVqxYoenTp6umpkaStG7dOi1ZskSbN29WUVGR6urqdPToUe3cuVOSNHnyZE2ePDnkMSZMmCCn06lZs2Zd6/gAAMA4E3G4KSkp0ZkzZ1RVVSWfz6e8vDw1NjYGLxru6OhQfPwXJ4QWL16s3bt3a+PGjdqwYYOysrLU0NCguXPnDt8oAAAA/r84Y4yJdieuld/vV2pqqrq7u0f0+pvMin16/8miEWsfQChec4DdRurzO+p3SwEAAAwnwg0AALAK4QYAAFiFcAMAAKxCuAHGoMyKfdHuAgDELMINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKwypHBTW1urzMxMORwOFRYW6siRI1etr6+vV3Z2thwOh3JycrR///6Q7U888YSys7N1/fXX66abbpLb7dbhw4eH0jUAADDORRxu9uzZo/LyclVXV6u1tVW5ubnyeDzq6uoKW3/o0CGVlpZq1apVamtrU3FxsYqLi9Xe3h6sue2227R9+3a9+eabevXVV5WZmak777xTZ86cGfrIAADAuBRnjDGR7FBYWKiFCxdq+/btkqRAIKCMjAytXbtWFRUVV9SXlJSop6dHe/fuDa5btGiR8vLytGPHjrCP4ff7lZqaql/96ldaunTpl/bpYn13d7dSUlIiGU5EMiv26f0ni0asfWCwxsuxOF7GCYxXI/X5HdGZm76+PrW0tMjtdn/RQHy83G63mpubw+7T3NwcUi9JHo9nwPq+vj7t3LlTqampys3NDVvT29srv98fsgAAAEgRhpuzZ8+qv79f6enpIevT09Pl8/nC7uPz+QZVv3fvXt1www1yOBz6x3/8RzU1NSktLS1smzU1NUpNTQ0uGRkZkQwDAABYLGbulvrGN76hY8eO6dChQ1q2bJnuu+++Aa/jqaysVHd3d3A5ceLEKPcWAADEqojCTVpamhISEtTZ2RmyvrOzU06nM+w+TqdzUPXXX3+9br31Vi1atEjPPPOMEhMT9cwzz4RtMzk5WSkpKSELAACAFGG4SUpKUn5+vrxeb3BdIBCQ1+uVy+UKu4/L5Qqpl6SmpqYB6y9tt7e3N5LuAQAAKDHSHcrLy7Vy5UotWLBABQUF2rp1q3p6elRWViZJWrFihaZPn66amhpJ0rp167RkyRJt3rxZRUVFqqur09GjR7Vz505JUk9Pj/7+7/9ed999t6ZOnaqzZ8+qtrZWJ0+e1PLly4dxqAAAYDyIONyUlJTozJkzqqqqks/nU15enhobG4MXDXd0dCg+/osTQosXL9bu3bu1ceNGbdiwQVlZWWpoaNDcuXMlSQkJCXr77bf13HPP6ezZs5o8ebIWLlyoV155RbfffvswDRMAAIwXEYcbSVqzZo3WrFkTdtuBAweuWLd8+fIBz8I4HA49//zzQ+kGAADAFWLmbikAAIDhQLgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArEK4AQAAViHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCqEGwAAYBXCDQAAsArhBgAAWIVwAwAArDKkcFNbW6vMzEw5HA4VFhbqyJEjV62vr69Xdna2HA6HcnJytH///uC2Tz/9VD/4wQ+Uk5Oj66+/XtOmTdOKFSt06tSpoXQNAACMcxGHmz179qi8vFzV1dVqbW1Vbm6uPB6Purq6wtYfOnRIpaWlWrVqldra2lRcXKzi4mK1t7dLkj7++GO1trbq8ccfV2trq55//nkdP35cd99997WNDAAAjEtxxhgTyQ6FhYVauHChtm/fLkkKBALKyMjQ2rVrVVFRcUV9SUmJenp6tHfv3uC6RYsWKS8vTzt27Aj7GK+//roKCgr0wQcfaMaMGV/aJ7/fr9TUVHV3dyslJSWS4UQks2Kf3n+yaMTaBwZrvByL42WcwHg1Up/fEZ256evrU0tLi9xu9xcNxMfL7Xarubk57D7Nzc0h9ZLk8XgGrJek7u5uxcXFadKkSWG39/b2yu/3hywAAABShOHm7Nmz6u/vV3p6esj69PR0+Xy+sPv4fL6I6j/55BP94Ac/UGlp6YAprqamRqmpqcElIyMjkmEAAACLxdTdUp9++qnuu+8+GWP09NNPD1hXWVmp7u7u4HLixIlR7CUAAIhliZEUp6WlKSEhQZ2dnSHrOzs75XQ6w+7jdDoHVX8x2HzwwQd66aWXrvq7t+TkZCUnJ0fSdQAAME5EdOYmKSlJ+fn58nq9wXWBQEBer1culyvsPi6XK6RekpqamkLqLwabd955R7/61a80efLkSLoFAAAQFNGZG0kqLy/XypUrtWDBAhUUFGjr1q3q6elRWVmZJGnFihWaPn26ampqJEnr1q3TkiVLtHnzZhUVFamurk5Hjx7Vzp07JX0ebP7yL/9Sra2t2rt3r/r7+4PX49x8881KSkoarrECAIBxIOJwU1JSojNnzqiqqko+n095eXlqbGwMXjTc0dGh+PgvTggtXrxYu3fv1saNG7VhwwZlZWWpoaFBc+fOlSSdPHlSL774oiQpLy8v5LFefvll/dmf/dkQhwYAAMajiMONJK1Zs0Zr1qwJu+3AgQNXrFu+fLmWL18etj4zM1MRftUOAADAgGLqbikAAIBrRbgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcANYIrNiX7S7AAAxgXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AADGKr3gYGsINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAGIf4/hTYjHADxBA+cADg2hFuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYhXADAACsQrgBAABWIdwAAACrEG4AIMbwZY7AtSHcAAAAqxBuAACAVQg3AADAKoQbAABgFcINAACwCuEGAABYZUjhpra2VpmZmXI4HCosLNSRI0euWl9fX6/s7Gw5HA7l5ORo//79Iduff/553XnnnZo8ebLi4uJ07NixoXQLAAAg8nCzZ88elZeXq7q6Wq2trcrNzZXH41FXV1fY+kOHDqm0tFSrVq1SW1ubiouLVVxcrPb29mBNT0+P7rjjDj311FNDHwkAwCp83w+GKuJws2XLFq1evVplZWWaM2eOduzYoYkTJ2rXrl1h67dt26Zly5Zp/fr1mj17tjZt2qT58+dr+/btwZoHH3xQVVVVcrvdQx8JAACAIgw3fX19amlpCQkh8fHxcrvdam5uDrtPc3PzFaHF4/EMWA8AAHAtIgo3Z8+eVX9/v9LT00PWp6eny+fzhd3H5/NFVD8Yvb298vv9IYvNODULAMDgjcm7pWpqapSamhpcMjIyot0lAAAQIyIKN2lpaUpISFBnZ2fI+s7OTjmdzrD7OJ3OiOoHo7KyUt3d3cHlxIkTQ24LAADYJaJwk5SUpPz8fHm93uC6QCAgr9crl8sVdh+XyxVSL0lNTU0D1g9GcnKyUlJSQhYAAABJSox0h/Lycq1cuVILFixQQUGBtm7dqp6eHpWVlUmSVqxYoenTp6umpkaStG7dOi1ZskSbN29WUVGR6urqdPToUe3cuTPY5kcffaSOjg6dOnVKknT8+HFJn5/1uZYzPAAAYPyJONyUlJTozJkzqqqqks/nU15enhobG4MXDXd0dCg+/osTQosXL9bu3bu1ceNGbdiwQVlZWWpoaNDcuXODNS+++GIwHEnS/fffL0mqrq7WE088MdSxAQCAcSjicCNJa9as0Zo1a8JuO3DgwBXrli9fruXLlw/Y3kMPPaSHHnpoKF0BAAAIMSbvlgLGIm7pB4DRQbgBAABWIdwAwCjgzB0wegg3AADAKoQbAFbhDAkAws0g8YYJAMDYQLgBAABWIdxYgjNLAAB8jnADAACsQrgBAABWIdwAAACrEG4AYARdfj0c18cBI49wAwAArEK4iSH8RAcAwLUj3MAahEMAgES4wSgifIxvPP8ARgvhBjGJD0IAw4H3kvGJcAMAAKxCuBll/BSBaOHYAzBeEG7GED6cAFwr3kcwHhBuAACAVQg3MYyfsJiDaGHeAYxlhBsAAGAVwg2GDT/tx6ZI/rZRrD6HsdovALGJcIMRwwcSMPp43QGEG+Cq+KCIHHMGINoINwAAwCqEGyBKbD/DcS3ji9W5idV+jVc8HxgI4QbDjjec4TcSc8rzZLfx+vxeHPd4HT8+R7gZhFh7kcRafxCZkX7+RvLNnWNvdI3V+R6r/YY9CDeW4s0Fw2kwxxPHHIBYQbgBAIRFYMVYRbiJQbyhRB/PwfCJ5EsEgVgSzWOV18m1IdyME7H0QhntvsTS2IHhZOOxbeOYrhVzEjnCjWVs/ynZtvFg5EVyzHB8xSbb39cw/Ag3GHFcjBq5WJ+PWO8fgPGNcDPMbPoJYyz3HbjcaB3PI/k4vCaBwSHcIKbw5h2K+Yiusf6FcMPV76G0k1mxL2T+xuocXiqWxhBLfYlFhJtxhhfE8GAeo2sszH+s9HG4+/Fl7Q3m7HWkbQCRItwMk7H2YhzqT2JjwUh+M+94u37IprFcq6F8SMeS4biwejjHO5bnLtp9j8Ydp9Eec6QIN8NorD35l7pa36M9rqG+sEb7DSnW3gBjpQ8YvJF6vkbi7E00PvBsPJ5jcUyx2KdIDSnc1NbWKjMzUw6HQ4WFhTpy5MhV6+vr65WdnS2Hw6GcnBzt378/ZLsxRlVVVZo6daquu+46ud1uvfPOO0PpGgYhFg7cwYSpaL/Rc2FobBvqHMbKF7NFcnYk0j6PxpmXoYjW49vyd9ZGM1BGK8AOl4jDzZ49e1ReXq7q6mq1trYqNzdXHo9HXV1dYesPHTqk0tJSrVq1Sm1tbSouLlZxcbHa29uDNf/wD/+gH//4x9qxY4cOHz6s66+/Xh6PR5988snQRxZlV/spPlbv2hiOfo3136WP9tmdWGo/1p6boZwJG+h1Fi4wD/TGPRzH8Jf1PdbmOlpsOl4vNxr9G8qvGmN93oZLxOFmy5YtWr16tcrKyjRnzhzt2LFDEydO1K5du8LWb9u2TcuWLdP69es1e/Zsbdq0SfPnz9f27dslfX7WZuvWrdq4caPuuecezZs3Tz/96U916tQpNTQ0XNPgRspIhIbhPJtwrQfvl30oDLWtkfRlP6lG81qZWHwziYU+jeR1XyMdsgcbjIazH6P1A9Jon/WJhWNxLIvkvW08zXViJMV9fX1qaWlRZWVlcF18fLzcbream5vD7tPc3Kzy8vKQdR6PJxhc3nvvPfl8Prnd7uD21NRUFRYWqrm5Wffff/8Vbfb29qq3tzf4/93d3ZIkv98fyXAGLdD7cfDffr9fgd6PQx5rbvUvQupnfL8+5L+X7xuur5euv9h+oPfjq7Z1+f6Xth+uP5dvv7SNi+sHqr28rfYfeq7Ydmn91cY+0OMP9JiXtzHj+/VXPP7l/b/88SNpI9w8hXsurvYcDPTfcP25vI3LH+fS/17sc7gxXG3+B3McDTSHlx8T4V4Dgx3/l7Uxt/oXav+hZ1BjGWj+Lh/f1Y6pgebg4rpLn49I9o/EQPsPdOyEez4uuvy9aCDhjqnL+3D5cT+Y/l8+hoHqv+y94PI+XrpfuPm4/HUQ7ni/+BgXj7FL5+rS/S+uv3gcXu3xw81fuH5c+jiXPv7Fxwj32XX5/lc7lsO9ji59vMtd7X384mMP5nGGw8U2jTHD27CJwMmTJ40kc+jQoZD169evNwUFBWH3mTBhgtm9e3fIutraWjNlyhRjjDG//vWvjSRz6tSpkJrly5eb++67L2yb1dXVRhILCwsLCwuLBcuJEyciiSNfKqIzN7GisrIy5GxQIBDQRx99pMmTJysuLm5YH8vv9ysjI0MnTpxQSkrKsLaNq2Puo4N5jw7mPTqY9+i4OO8dHR2Ki4vTtGnThrX9iMJNWlqaEhIS1NnZGbK+s7NTTqcz7D5Op/Oq9Rf/29nZqalTp4bU5OXlhW0zOTlZycnJIesmTZoUyVAilpKSwoEfJcx9dDDv0cG8RwfzHh2pqakjMu8RXVCclJSk/Px8eb3e4LpAICCv1yuXyxV2H5fLFVIvSU1NTcH6mTNnyul0htT4/X4dPnx4wDYBAAAGEvGvpcrLy7Vy5UotWLBABQUF2rp1q3p6elRWViZJWrFihaZPn66amhpJ0rp167RkyRJt3rxZRUVFqqur09GjR7Vz505JUlxcnL73ve/p7/7u75SVlaWZM2fq8ccf17Rp01RcXDx8IwUAAONCxOGmpKREZ86cUVVVlXw+n/Ly8tTY2Kj09HRJUkdHh+LjvzghtHjxYu3evVsbN27Uhg0blJWVpYaGBs2dOzdY8zd/8zfq6enRd77zHZ07d0533HGHGhsb5XA4hmGI1yY5OVnV1dVX/BoMI4+5jw7mPTqY9+hg3qNjpOc9zpjhvv8KAAAgevjbUgAAwCqEGwAAYBXCDQAAsArhBgAAWIVw8yVqa2uVmZkph8OhwsJCHTlyJNpdGtP+53/+R3/xF3+hadOmKS4u7oo/jmqMUVVVlaZOnarrrrtObrdb77zzTkjNRx99pAceeEApKSmaNGmSVq1apQsXLoziKMaempoaLVy4UDfeeKOmTJmi4uJiHT9+PKTmk08+0aOPPqrJkyfrhhtu0Le//e0rvoCzo6NDRUVFmjhxoqZMmaL169frs88+G82hjClPP/205s2bF/yCOJfLpZ///OfB7cz56HjyySeDXztyEXM//J544gnFxcWFLNnZ2cHtozrnw/rHHCxTV1dnkpKSzK5du8xvfvMbs3r1ajNp0iTT2dkZ7a6NWfv37zd/+7d/a55//nkjybzwwgsh25988kmTmppqGhoazP/+7/+au+++28ycOdP84Q9/CNYsW7bM5Obmmtdee8288sor5tZbbzWlpaWjPJKxxePxmJ/85Cemvb3dHDt2zHzzm980M2bMMBcuXAjWPPzwwyYjI8N4vV5z9OhRs2jRIrN48eLg9s8++8zMnTvXuN1u09bWZvbv32/S0tJMZWVlNIY0Jrz44otm37595ne/+505fvy42bBhg5kwYYJpb283xjDno+HIkSMmMzPTzJs3z6xbty64nrkfftXV1eb22283p0+fDi5nzpwJbh/NOSfcXEVBQYF59NFHg//f399vpk2bZmpqaqLYK3tcHm4CgYBxOp3mRz/6UXDduXPnTHJysvnZz35mjDHmt7/9rZFkXn/99WDNz3/+cxMXF2dOnjw5an0f67q6uowkc/DgQWPM5/M8YcIEU19fH6x56623jCTT3NxsjPk8mMbHxxufzxesefrpp01KSorp7e0d3QGMYTfddJP5l3/5F+Z8FJw/f95kZWWZpqYms2TJkmC4Ye5HRnV1tcnNzQ27bbTnnF9LDaCvr08tLS1yu93BdfHx8XK73Wpubo5iz+z13nvvyefzhcx5amqqCgsLg3Pe3NysSZMmacGCBcEat9ut+Ph4HT58eNT7PFZ1d3dLkm6++WZJUktLiz799NOQuc/OztaMGTNC5j4nJyf4hZ2S5PF45Pf79Zvf/GYUez829ff3q66uTj09PXK5XMz5KHj00UdVVFQUMscSx/tIeueddzRt2jR97Wtf0wMPPKCOjg5Joz/nY/Kvgo+Gs2fPqr+/P2SSJSk9PV1vv/12lHplN5/PJ0lh5/ziNp/PpylTpoRsT0xM1M033xyswdUFAgF973vf0x//8R8Hvync5/MpKSnpij9Ae/nch3tuLm5DeG+++aZcLpc++eQT3XDDDXrhhRc0Z84cHTt2jDkfQXV1dWptbdXrr79+xTaO95FRWFioZ599VrNmzdLp06f1wx/+UH/yJ3+i9vb2UZ9zwg0wzjz66KNqb2/Xq6++Gu2ujAuzZs3SsWPH1N3drf/4j//QypUrdfDgwWh3y2onTpzQunXr1NTUFBN/xme8uOuuu4L/njdvngoLC3XLLbfo3//933XdddeNal/4tdQA0tLSlJCQcMWV3J2dnXI6nVHqld0uzuvV5tzpdKqrqytk+2effaaPPvqI52UQ1qxZo7179+rll1/WV7/61eB6p9Opvr4+nTt3LqT+8rkP99xc3IbwkpKSdOuttyo/P181NTXKzc3Vtm3bmPMR1NLSoq6uLs2fP1+JiYlKTEzUwYMH9eMf/1iJiYlKT09n7kfBpEmTdNttt+ndd98d9eOdcDOApKQk5efny+v1BtcFAgF5vV65XK4o9sxeM2fOlNPpDJlzv9+vw4cPB+fc5XLp3LlzamlpCda89NJLCgQCKiwsHPU+jxXGGK1Zs0YvvPCCXnrpJc2cOTNke35+viZMmBAy98ePH1dHR0fI3L/55psh4bKpqUkpKSmaM2fO6AzEAoFAQL29vcz5CFq6dKnefPNNHTt2LLgsWLBADzzwQPDfzP3Iu3Dhgn7/+99r6tSpo3+8R3w59DhSV1dnkpOTzbPPPmt++9vfmu985ztm0qRJIVdyIzLnz583bW1tpq2tzUgyW7ZsMW1tbeaDDz4wxnx+K/ikSZPMf/3Xf5k33njD3HPPPWFvBf+jP/ojc/jwYfPqq6+arKwsbgX/Eo888ohJTU01Bw4cCLlN8+OPPw7WPPzww2bGjBnmpZdeMkePHjUul8u4XK7g9ou3ad55553m2LFjprGx0XzlK1/h1tirqKioMAcPHjTvvfeeeeONN0xFRYWJi4szv/zlL40xzPlouvRuKWOY+5Hw2GOPmQMHDpj33nvP/PrXvzZut9ukpaWZrq4uY8zozjnh5kv80z/9k5kxY4ZJSkoyBQUF5rXXXot2l8a0l19+2Ui6Ylm5cqUx5vPbwR9//HGTnp5ukpOTzdKlS83x48dD2vjwww9NaWmpueGGG0xKSoopKysz58+fj8Joxo5wcy7J/OQnPwnW/OEPfzB//dd/bW666SYzceJEc++995rTp0+HtPP++++bu+66y1x33XUmLS3NPPbYY+bTTz8d5dGMHX/1V39lbrnlFpOUlGS+8pWvmKVLlwaDjTHM+Wi6PNww98OvpKTETJ061SQlJZnp06ebkpIS8+677wa3j+acxxljzJDPOQEAAMQYrrkBAABWIdwAAACrEG4AAIBVCDcAAMAqhBsAAGAVwg0AALAK4QYAAFiFcAMAAKxCuAEAAFYh3AAAAKsQbgAAgFUINwAAwCr/DyFlA4XxyC59AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "OH_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse = False)\n",
    "#One-hot encode dataframe (necessary because originally occured in pipeline not called here)\n",
    "OH_X_cols = pd.DataFrame(OH_encoder.fit_transform(X[object_cols])) \n",
    "#readd index \n",
    "OH_X_cols.index = X.index\n",
    "#remove categorical columns from X\n",
    "oh_X = X.drop(object_cols, axis = 1)\n",
    "#add one-hot encoded columns to main dataframe\n",
    "temp_X = pd.concat([oh_X, OH_X_cols], axis = 1)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = n_value, random_state = 0, n_jobs = -1, criterion = \"absolute_error\")\n",
    "model.fit(temp_X, y)\n",
    "importance = model.feature_importances_\n",
    "\n",
    "#visualise importance \n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1166.243570753603\n",
      "       TOPFRONT  SOLOTHER  SWAMPCOL  USENOTMOIST  HHSEX  SWIMPOOL  OTHROOMS  \\\n",
      "DOEID                                                                         \n",
      "10001         2         0         0           -2      2         0         4   \n",
      "10002        -2         0         0           -2      1         0         2   \n",
      "10003         2         0         0           -2      1         0         5   \n",
      "10004         1         0        -2           -2      1         0         4   \n",
      "10005         1         0        -2            1      2         0         3   \n",
      "...         ...       ...       ...          ...    ...       ...       ...   \n",
      "15682        -2         0        -2           -2      1        -2         2   \n",
      "15683         1         0         0           -2      1         0         2   \n",
      "15684        -2         0        -2           -2      1        -2         2   \n",
      "15685         1         0         0           -2      1         0         2   \n",
      "15686        -2         0        -2           -2      2        -2         2   \n",
      "\n",
      "       STUDIO  DISHWASH  TEMPHOMEAC  TEMPHOME  MICRO  TEMPGONE  DIVISION  \\\n",
      "DOEID                                                                      \n",
      "10001      -2         1          78        69      1        69        10   \n",
      "10002      -2         0          76        75      1        70         7   \n",
      "10003      -2         1          75        70      2        70         6   \n",
      "10004      -2         0          76        68      1        65         4   \n",
      "10005      -2         0          72        68      1        62         2   \n",
      "...       ...       ...         ...       ...    ...       ...       ...   \n",
      "15682       0         0          76        72      1        72         3   \n",
      "15683      -2         0          73        75      1        65         6   \n",
      "15684       0         0          67        67      1        67         3   \n",
      "15685      -2         1          74        72      1        65         7   \n",
      "15686       0         1          80        80      1        75         3   \n",
      "\n",
      "       DOOR1SUM  DUALOVENFUEL  TEMPGONEAC  USEWWAC  NHSLDMEM  BEDROOMS  \n",
      "DOEID                                                                   \n",
      "10001         2            -2          80       -2         4         3  \n",
      "10002         0            -2          80        1         2         2  \n",
      "10003         1            -2          85        4         4         4  \n",
      "10004         4            -2          85       -2         1         3  \n",
      "10005         1            -2          78       -2         3         3  \n",
      "...         ...           ...         ...      ...       ...       ...  \n",
      "15682         0            -2          76        4         1         1  \n",
      "15683         0            -2          73        2         2         3  \n",
      "15684         0            -2          67        1         1         1  \n",
      "15685         0            -2          80       -2         2         3  \n",
      "15686         1            -2          75       -2         1         1  \n",
      "\n",
      "[5686 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "importance_dict = {}\n",
    "\n",
    "for i, v in enumerate(importance):\n",
    "    importance_dict[i] = v\n",
    "\n",
    "\n",
    "\n",
    "#get top 30 most important features \n",
    "sort = sorted(importance_dict, key=importance_dict.get, reverse=True)\n",
    "top_30 = [str(X.columns[i]) for i in sort[10:30]]\n",
    "\n",
    "\n",
    "\n",
    "#get column name for each index position \n",
    "\n",
    "\n",
    "X_copy = X.copy()\n",
    "\n",
    "X_top_30 = X_copy.loc[:,top_30]\n",
    "print(X_top_30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 30 model \n",
    "Uses only the 30 most important features to reduce processing time. Comes at relatively small decrease in model accuracy. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#pre-processing\n",
    "#check if any columns contain characters\n",
    "s = (X_top_30.dtypes == \"object\")\n",
    "object_cols_T30 = list(s[s].index)\n",
    "print(object_cols_T30) \n",
    "\n",
    "preprocessor_T30 = ColumnTransformer(transformers = [(\"cat\", categorical_transformer, object_cols_T30)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 331, in fit\n    X, y = self._validate_data(\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 918, in check_array\n    raise ValueError(\nValueError: Found array with 0 feature(s) (shape=(4548, 0)) while a minimum of 1 is required by RandomForestRegressor.\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 331, in fit\n    X, y = self._validate_data(\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 918, in check_array\n    raise ValueError(\nValueError: Found array with 0 feature(s) (shape=(4549, 0)) while a minimum of 1 is required by RandomForestRegressor.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\evanm\\OneDrive\\Documents\\Python resources\\Machine learning\\electricty_ML_main.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#X21sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m n_value \u001b[39min\u001b[39;00m N_VALUES:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#X21sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mfor\u001b[39;00m learning_value \u001b[39min\u001b[39;00m LEARNING_VALUES: \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#X21sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         score \u001b[39m=\u001b[39m get_score_M2(n_value, learning_value)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#X21sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         all_values_T30\u001b[39m.\u001b[39mappend(score)\n",
      "\u001b[1;32mc:\\Users\\evanm\\OneDrive\\Documents\\Python resources\\Machine learning\\electricty_ML_main.ipynb Cell 13\u001b[0m in \u001b[0;36mget_score_M2\u001b[1;34m(n_value, learning_value)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m my_pipeline \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39mpipeline\u001b[39m.\u001b[39mPipeline(steps \u001b[39m=\u001b[39m[\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mpreprocessor\u001b[39m\u001b[39m\"\u001b[39m, preprocessor_T30),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m, RandomForestRegressor(n_estimators \u001b[39m=\u001b[39m n_value, random_state \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, n_jobs \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, criterion \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mabsolute_error\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m ])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#X21sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m#assess model using cross-validation\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#X21sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m scores \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m*\u001b[39m cross_val_score(my_pipeline, X, y, cv \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m, scoring \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mneg_mean_absolute_error\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#X21sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(scores\u001b[39m.\u001b[39mmean())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/evanm/OneDrive/Documents/Python%20resources/Machine%20learning/electricty_ML_main.ipynb#X21sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mreturn\u001b[39;00m(scores\u001b[39m.\u001b[39mmean())\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32mc:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 331, in fit\n    X, y = self._validate_data(\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 918, in check_array\n    raise ValueError(\nValueError: Found array with 0 feature(s) (shape=(4548, 0)) while a minimum of 1 is required by RandomForestRegressor.\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 331, in fit\n    X, y = self._validate_data(\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 596, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1074, in check_X_y\n    X = check_array(\n  File \"c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 918, in check_array\n    raise ValueError(\nValueError: Found array with 0 feature(s) (shape=(4549, 0)) while a minimum of 1 is required by RandomForestRegressor.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "\n",
    "#create values to alternate through to check for best parameters\n",
    "N_VALUES = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "LEARNING_VALUES = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "#create dictionary to assign results to \n",
    "model_dict_T30 = {}\n",
    "all_values_T30  = []\n",
    "\n",
    "def get_score_M2(n_value, learning_value):\n",
    "\n",
    "    #model = XGBRegressor(n_estimators = n_value,  learning_rate = learning_value, n_jobs = 4)\n",
    "\n",
    "    #create pipeline \n",
    "    my_pipeline = sklearn.pipeline.Pipeline(steps =[\n",
    "        (\"preprocessor\", preprocessor_T30),\n",
    "        (\"model\", RandomForestRegressor(n_estimators = n_value, random_state = 0, n_jobs = -1, criterion = \"absolute_error\"))\n",
    "    ])\n",
    "\n",
    "    #assess model using cross-validation\n",
    "    scores = -1* cross_val_score(my_pipeline, X, y, cv = 5, scoring = \"neg_mean_absolute_error\")\n",
    "    print(scores.mean())\n",
    "    return(scores.mean())\n",
    "\n",
    "for n_value in N_VALUES:\n",
    "    for learning_value in LEARNING_VALUES: \n",
    "        score = get_score_M2(n_value, learning_value)\n",
    "\n",
    "        all_values_T30.append(score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\evanm\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.118030151663075\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44d185f371fdda112848cc952b3838de71c0600367086048220c58996696b225"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
